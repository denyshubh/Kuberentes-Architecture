# Setup Crio in Worker Nodes
https://kubernetes.io/docs/setup/production-environment/container-runtimes/#cri-o

1. Use the modprobe command to load the overlay and the br_netfilter modules
```
sudo modprobe overlay
sudo modprobe br_netfilter
```

2. Create a sysctl config file to enable IP forwarding and netfilter settings persistently across reboots.
```
sudo vim /etc/sysctl.d/99-kubernetes-cri.conf

net.bridge.bridge-nf-call-iptables=1
net.ipv4.ip_forward=1
net.bridge.bridge-nf-call-ip6tables=1
```

3. Use the sysctl command to apply the config file.
```
sysctl --system
```

4. Install a dependent software package

```
apt-get install -y software-properties-common
```
### Install CRI-O

https://github.com/cri-o/cri-o/blob/master/install.md

To get you os and other information run the below command
```
hostnamectl
```

```
export VERSION=1.17
OS=xUbuntu_18.04
```

```
sudo su

{
echo "deb https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/$OS/ /" > /etc/apt/sources.list.d/devel:kubic:libcontainers:stable.list
echo "deb http://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/$VERSION/$OS/ /" > /etc/apt/sources.list.d/devel:kubic:libcontainers:stable:cri-o:$VERSION.list

curl -L https://download.opensuse.org/repositories/devel:kubic:libcontainers:stable:cri-o:$VERSION/$OS/Release.key | apt-key add -
curl -L https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/$OS/Release.key | apt-key add -

apt-get update
apt-get install cri-o cri-o-runc
}
```
### Install Conmon
https://github.com/containers/conmon

There is a hard coded path for theconmonbinary which does not match Ubuntu 18.04. Update thecrio.conffile to use the correct binary path
```
which conmon
```

Edit the/etc/crio/crio.conf file to use the proper binary path. Also configure registries. Unlike Docker we must declare where to find images other than the core Kubernetes images.  Be aware this can be done in a few places such as /etc/containers/registries.d.

```
sudo vi /etc/crio/crio.conf
```

...

Path to the conmon binary, used for monitoring the OCI runtime.
```
conmon = "/usr/bin/conmon"         #<-- Edit this line. Around line 91....

registries = [                     #<-- Edit and add registries. Around line 258
  "docker.io",
  "quay.io",
  "registry.fedoraproject.org",
]
```
...

```
{
sudo systemctl daemon-reload
sudo systemctl enable crio
sudo systemctl start crio
}
```
Troubleshoot:

1. Install runc
2. Edit runc path in /etc/crio/crio.conf


## Kubelet Config File
```
KUBELET_EXTRA_ARGS=--feature-gates="AllAlpha=false,RunAsGroup=true" \
--container-runtime=remote \
--cgroup-driver=systemd \
--container-runtime-endpoint='unix:///var/run/crio/crio.sock' \
--runtime-request-timeout=5m
```


## ---------- Provisioning a Kubernetes Worker Node ----------------------

Install the OS dependencies:

{
  sudo apt-get update
  sudo apt-get -y install socat conntrack ipset
}
The socat binary enables support for the kubectl port-forward command.

Disable Swap
By default the kubelet will fail to start if swap is enabled. It is recommended that swap be disabled to ensure Kubernetes can provide proper resource allocation and quality of service.

Verify if swap is enabled:

sudo swapon --show
If output is empthy then swap is not enabled. If swap is enabled run the following command to disable swap immediately:

sudo swapoff -a
To ensure swap remains off after reboot consult your Linux distro documentation.


Download and Install Worker Binaries
wget -q --show-progress --https-only --timestamping \
  https://github.com/kubernetes-sigs/cri-tools/releases/download/v1.18.0/crictl-v1.18.0-linux-amd64.tar.gz \
  https://github.com/opencontainers/runc/releases/download/v1.0.0-rc91/runc.amd64 \
  https://github.com/containernetworking/plugins/releases/download/v0.8.6/cni-plugins-linux-amd64-v0.8.6.tgz \
  https://storage.googleapis.com/kubernetes-release/release/v1.18.6/bin/linux/amd64/kubectl \
  https://storage.googleapis.com/kubernetes-release/release/v1.18.6/bin/linux/amd64/kube-proxy \
  https://storage.googleapis.com/kubernetes-release/release/v1.18.6/bin/linux/amd64/kubelet


Create the installation directories:

sudo mkdir -p \
  /etc/cni/net.d \
  /opt/cni/bin \
  /var/lib/kubelet \
  /var/lib/kube-proxy \
  /var/lib/kubernetes \
  /var/run/kubernetes

Install the worker binaries:

{
  tar -xvf crictl-v1.18.0-linux-amd64.tar.gz
  sudo tar -xvf cni-plugins-linux-amd64-v0.8.6.tgz -C /opt/cni/bin/
  sudo mv runc.amd64 runc
  chmod +x crictl kubectl kube-proxy kubelet runc 
  sudo mv crictl kubectl kube-proxy kubelet runc /usr/local/bin/
}


### Configure Pod Networking

1. Deciding which pod network to use for Container Networking Interface (CNI) should take into account the expected demands on the cluster.  There can be only one pod network per cluster, although the CNI-Genie project is trying to change this.The network must allow container-to-container, pod-to-pod, pod-to-service, and external-to-service communications. As Docker uses host-private networking, using the docker0 virtual bridge and veth interfaces would require being on that host to communicate. We will use Calico as a network plugin which will allow us to use Network Policies later.  Currently Calico does not deploy using CNI by default. Newer versions of Calico have included RBAC in the main file.  Once downloaded look for the expected IPV4 range for containers to use in the configuration file.
```
wget https://docs.projectcalico.org/manifests/calico.yaml
```

2. Use less to page through the file.  Look for the IPV4 pool assigned to the containers.  There are many different configuration settings in this file.  Take a moment to view the entire file.  The CALICO_IPV4POOL_CIDR should have the value same as you have configured earlier for pod networking. In our case it is 10.200.0.0/16 
It should not conflict with the service-cidr. Also, Avoid conflicts with existing IP ranges of the instance.

### Configure Kubelet

HOSTNAME=$(hostname -s)

{
  sudo mv ${HOSTNAME}-key.pem ${HOSTNAME}.pem /var/lib/kubelet/
  sudo mv ${HOSTNAME}.kubeconfig /var/lib/kubelet/kubeconfig
  sudo mv ca.pem /var/lib/kubernetes/
}

kubelet-config.yaml

cat <<EOF | sudo tee /var/lib/kubelet/kubelet-config.yaml
kind: KubeletConfiguration
apiVersion: kubelet.config.k8s.io/v1beta1
authentication:
  anonymous:
    enabled: false
  webhook:
    enabled: true
  x509:
    clientCAFile: "/var/lib/kubernetes/ca.pem"
authorization:
  mode: Webhook
clusterDomain: "cluster.local"
clusterDNS:
  - "10.32.0.10"
podCIDR: "10.200.0.0/20"
resolvConf: "/run/systemd/resolve/resolv.conf"
runtimeRequestTimeout: "15m"
feature-gates: "AllAlpha=false,RunAsGroup=true"
cgroup-driver: systemd
tlsCertFile: "/var/lib/kubelet/${HOSTNAME}.pem"
tlsPrivateKeyFile: "/var/lib/kubelet/${HOSTNAME}-key.pem"
EOF


The resolvConf configuration is used to avoid loops when using CoreDNS for service discovery on systems running systemd-resolved.

Create the kubelet.service systemd unit file:

cat <<EOF | sudo tee /etc/systemd/system/kubelet.service
[Unit]
Description=Kubernetes Kubelet
Documentation=https://github.com/kubernetes/kubernetes
After=crio.service
Requires=crio.service

[Service]
ExecStart=/usr/local/bin/kubelet \\
  --config=/var/lib/kubelet/kubelet-config.yaml \\
  --container-runtime=remote \\
  --container-runtime-endpoint='unix:///var/run/crio/crio.sock' \\
  --image-pull-progress-deadline=2m \\
  --kubeconfig=/var/lib/kubelet/kubeconfig \\
  --network-plugin=cni \\
  --register-node=true \\
  --hostname-override=${HOSTNAME} \\
  --v=2
Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target
EOF

{
  sudo systemctl daemon-reload
  sudo systemctl enable kubelet
  sudo systemctl start kubelet
}


# Configure Kube-proxy

sudo mv kube-proxy.kubeconfig /var/lib/kube-proxy/kubeconfig

cat <<EOF | sudo tee /var/lib/kube-proxy/kube-proxy-config.yaml
kind: KubeProxyConfiguration
apiVersion: kubeproxy.config.k8s.io/v1alpha1
clientConnection:
  kubeconfig: "/var/lib/kube-proxy/kubeconfig"
mode: "iptables"
clusterCIDR: "10.200.0.0/16"
EOF



cat <<EOF | sudo tee /etc/systemd/system/kube-proxy.service
[Unit]
Description=Kubernetes Kube Proxy
Documentation=https://github.com/kubernetes/kubernetes

[Service]
ExecStart=/usr/local/bin/kube-proxy \\
  --config=/var/lib/kube-proxy/kube-proxy-config.yaml
Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target
EOF


{
  sudo systemctl daemon-reload
  sudo systemctl enable kube-proxy
  sudo systemctl start kube-proxy
}
